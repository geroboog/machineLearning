{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "A1_ReportDraft.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bRwQ9JwiSq3",
        "colab_type": "text"
      },
      "source": [
        "# Draft and Experiment Area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-p-eY9diSq5",
        "colab_type": "text"
      },
      "source": [
        "1. First impression\n",
        "    * What is my chosen paper to read?\n",
        "    * What type of the main contribution the paper has made?\n",
        "        - A theory or proposition (revealing something, from unknown to known)\n",
        "        - A method or algorithm (inventing a technique, from undoable to doable)\n",
        "\n",
        "    * _Before_ reading the main body of the paper, write down your first impression  obtained from its abstract and short introduction.\n",
        "    * Why does the paper attract you, such as, How it surprised you? Why do you think it addresses an important topic that will be helpful in your future study of machine learning?\n",
        "    \n",
        "2. Read the paper abstract and introduction, list here all the notions that you don't know the precise meaning. If you think you have completed your list,  compare the list with people around you who have chosen the same or a similar paper.\n",
        "\n",
        "3. (During the next 7 days) Re-consider the central problem of the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpPHMAXbiSq6",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on \"Gradient-Based Learning Applied to Document Recognition\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP3uHEAliSq6",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "The review report is about giving an overview of the research paper- \"Gradient-Based Learning Applied to Document Recognition\"[1] which designed an innovating and successful multi-module architecture called Graph Transform Network for pattern recognition and also evaluate the performance of the convolutional nerual network for identifying handwritten characters. The reson why this paper is selected to be analyzed is that this paper not only introduces how to achieve image identification/pattern recognition but also describe how to build a graph tranformer system in detail, which is good for the future study in deep learning and image \n",
        "processing, which also explains how gradient-based learning algorithm like CNN is feasible for image recognition. However, even many innovations and improvements were achieved in this research, there are still some limitaion of the research. In this review paper, firstly, the summarized content of the research will be described in the content section. Secondly, the innovation of the research will be explained detailly after the content section. Thridly, from the evaluation part of original paper, the technical quality will be talked about. Fourthly, this report will arrive to the application of the new technology. Finally, the last section will analyze how the author orgnized the report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afQWhuOKiSq7",
        "colab_type": "text"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z5hux4SiSq7",
        "colab_type": "text"
      },
      "source": [
        "In the past, most pattern recognition systems are built using a combination of automatic learning techniques and hand-crafted algorithms. This literature introduces two remarkable graph transform networks(GTN) with multi-modules for segmenting, classifying, and resequencing the handwritten characters string, which elistimates the manual work and increase the accuracy for the pattern recognition.On the one hand, the first GTN is combined by 4 modules the Segmentation Transformer, Character Recognition Transformer(CRT), Composition Transformer, and Beam Search Transformer. Specifically, the segmentation transformer will uses Heuristic Over-segmentaion algorithm to devide the whole picture to a set of arcs(segments) as the input of CRT. And then the CRT which is the most important part of the research is consitubed by the CNN trained with Gradient-based learning and back-propagation method. For training the CNN, such as the LeNet-5 with 7 layers as the innovated CNN described detailly in the research, the input image is very large and consists of many pixels. For example, a fully connected network with 100 hidden units contains thousands of weights. So, the CNN will use its particular function-convolution for extracting the feature data from the original image to be the feature maps, so that the gradient-based learning layer and back-propogation can handle the data.  Next, the author suggests to use the grammar graph and Viterbi algorithm to implement the composition transformer and the beam search transformer. \n",
        "\n",
        "On the other hand, the second GTN stucture uses the Space-Displacement Neural Network which is kind of CNN with the ability to automatic scan possible character positions of the orignal image to replace the segmentation transformer and Character Recognition Transformer. Besides, the compostion transfrom is separated to be two level compostion transformer-character and word level, because the identified characters of the SDNN's output sets is uncertained, which is depended on the identified possible positions of characters. For character level, with the help of CNN, the Hidden Markov Models(HMM) which is famous for classical speech recognition can be used in the character-level composition with reduced computational cost. For the word level, this GTN can be used for identified continiously on-line handwritten strings, so after transforming characters, the architure will recombinate the words with a language model and output the interpretation graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcrV1o8LiSq8",
        "colab_type": "text"
      },
      "source": [
        "## Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq8S26DliSq9",
        "colab_type": "text"
      },
      "source": [
        "The most important and intelligent innovation of the research is to use the CNN to elistimate the hand-crafted part, because before the research of the author, most pattren recognition system is built in a semi-automatic architecture, which means the graph feature extraction is manual work. Therefore, It is really remarkable for the importance and innovation of using the specialty of LeNet-5 CNN to achieve automatic feature map extracting and recognition in the research.\n",
        "\n",
        "In addition, there are two kind of GTNs that designed and experimented by the authors in the research. The authors seperate the whole transformer network to be modules by OOP method, and uses back-propagation method to compute the derivatives in the system. The innovation of the first GTN is to increase the accuracy of pattern recognition and combine the Heuristic Over-Segmentation, CNN, Viterbi algorithm and Grammar graph to fully automical transform the graph to be words. The innovation of the second GTN is to remove the segmentation part of the first GTN by using SDNN to replace the CNN and also use the HMM to achieve the characters recomposition module. \n",
        "\n",
        "What's more, the authors designed the generalized transduction for achieving the composition transform. The generalized transduction is divided as Check, Fprod, and Bprod function. For determining whether corresponding arc(s) should be created in the output graph, the Check function will compare the arcs(from recognition part) and output a boolean value. The Fprod function will be activated when the corresponding arc(s) should be built and creates new arcs and nodes between the up node and down node in the output new graph. The Bprod is called during training for propagating gradient data from the output subgraph to the data structures on the arc1 and arc2( from the recognition layer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOqtiUu6iSq9",
        "colab_type": "text"
      },
      "source": [
        "## Technical quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGPw647viSq-",
        "colab_type": "text"
      },
      "source": [
        "The technology of the research is in high quality. Generally speaking, the authors do the literature review for past methods to the pattern recognition for supporting that the pattern recognition is achieved by the hybrid-technology which combines automatic machine learning algorithm and manual feature extraction method. In the C part of the section I, the authors references several examples like the Boltzmann machines to prove that the multi-layer neural network achieved with gradient-back propagation algorithm is feasible for classifying non-linear objects, and the artificial image feature extraction can be replaced by the inner function of CNN. In my opinion, the quality of this part is good enough to explain why NN is reliable for handeling such non-linear classification.\n",
        "\n",
        "Besides, for explaining how CNN deal with 2D graph to be the OUTPUT, in the section II, the author draws the structure of the LeNet-5 CNN to show the inner cooperation between convolutions layers, subsampling layers, full connection layers and the output layer. For comparing the performance of CNN with other classifying algorithm, the author experimented more than 11 algorithm like SVM, K-NN, PCA, Tangent Distance and LeNet-1 to classify the single character image to be character, and the LeNet-5 shows the best performance(0.95% errors) without the help of articially distorted examples(LeNet-5 0.8% errors) and boosting method(LeNet-4 0.7% errors). In addition, the figure 13 of the section II shows the ability of LeNet-5 to identify the character from images with various degress of noisy conditions. What's more, For the GTN with SDNN approach, this hybrid and innovative architecture also tested with the normal and noised images, and provided with well-structured architecture diagram and algorithm coding like the generalized-composition function which is for compositing the recognized graphs to be a new graph. However, the GTNs sometimes still can not recognize some handwritten character because the written style of different people are different. So, in my opinion, the author should deal with this situation in the report or suggest some methodology for further research for this case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z-F2o36iSq_",
        "colab_type": "text"
      },
      "source": [
        "## Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LduLS9pIiSq_",
        "colab_type": "text"
      },
      "source": [
        "From the paper, it is known that this system is already used in the commercial area in the NCR Corporation line of the bank's check recognition systems which is used for recognizing the print or handwritten character from checks. The application has been realized and approved, because, in the United States, the system has read millions of checks per month in various banks. With the powerful document recognition ability, the system can not only be used for checks checking but also can be used for scanning the handwritten or printing bank statement as the data resource for fraud detection. \n",
        "\n",
        "According to the Australian Payments Network Limited 2018, the australia losses 598 thousands dollar in 2012. However, this number shows a linear increase during the past years. In 2017, 748 thousands dollar losses due to the fraud data. With the document recognition system, the bank staffs can just scan the materials into the system, and don't have to maurally input the data into the banking system. After scanning the data, it may be used with fraud detection system like the financial statements fraud detection system designed by Humphery(2011). With the document recognition system, the time of manual input will be reduced, which means it can totally reduces the staffs who needs to input data by hand every day."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVADqy9OiSrA",
        "colab_type": "text"
      },
      "source": [
        "## Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oJfVdQLiSrB",
        "colab_type": "text"
      },
      "source": [
        "The overall structure of the paper is well. In the introduction section, the authors introduces several fundemantal knowledages about the old-fashioned semi-automactic pattern recognition system and the new technologies of machine learning, which makes the readers understand the history and limitation of pattern recognition methdology. Besides, the author uses many diagram for presenting the clear structure of many algorithms. For exmaple, the LeNet-5, first GTN, GTN with SDNN are all displayed with a well-structured diagram. However, the authors did high-light the significant parts of the formulas in the paper, In this situation if a reader is a beginner in machine learning area, he or she will feel very confused when they try to understand the formula. For example, the formulas of fireworks algorithm are clearly explained by Tan Y.(2010) by high-lighting the keywords of the formulas. What's more, the author should summarized every arguments of the formula after it is discribed detailly, so that readers can compare the understanding of detail with the summary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFAaLVfViSrB",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "[LEC98][1]: Lecun, Y., et al. 1998. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, vol. 50,no. 11 pp. 2278-2324.\n",
        "\n",
        "[2]:Australian Payments Network Limited 2018, AustralianPaymentCardFraud-2018, Australian Payments Network Limited,  viewed 1 June 2019,  <https://www.auspaynet.com.au/sites/default/files/2018-08/AustralianPaymentCardFraud-2018-Report.pdf>.\n",
        "Turban, E., Sharda, R. & Delen, D. 2010, Decision Support and Business Intelligence Systems, Ninth edn, Prentice Hall Press.\n",
        "\n",
        "[3]Humpherys, S.L., Moffitt, K.C., Burns, M.B., Burgoon, J.K. & Felix, W.F. 2011, 'Identification of fraudulent financial statements using linguistic credibility analysis', Decision Support Systems, vol. 50, no. 3, pp. 585-94.\n",
        "\n",
        "[4]:Tan Y., Shi Y., Tan K.C. 2010, Advances in Swarm Intelligence, 1st edn, Springer, Berlin, Heidelberg."
      ]
    }
  ]
}