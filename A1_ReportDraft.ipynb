{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "A1_ReportDraft.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bRwQ9JwiSq3",
        "colab_type": "text"
      },
      "source": [
        "# Draft and Experiment Area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-p-eY9diSq5",
        "colab_type": "text"
      },
      "source": [
        "1. First impression\n",
        "    * What is my chosen paper to read?\n",
        "    * What type of the main contribution the paper has made?\n",
        "        - A theory or proposition (revealing something, from unknown to known)\n",
        "        - A method or algorithm (inventing a technique, from undoable to doable)\n",
        "\n",
        "    * _Before_ reading the main body of the paper, write down your first impression  obtained from its abstract and short introduction.\n",
        "    * Why does the paper attract you, such as, How it surprised you? Why do you think it addresses an important topic that will be helpful in your future study of machine learning?\n",
        "    \n",
        "2. Read the paper abstract and introduction, list here all the notions that you don't know the precise meaning. If you think you have completed your list,  compare the list with people around you who have chosen the same or a similar paper.\n",
        "\n",
        "3. (During the next 7 days) Re-consider the central problem of the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpPHMAXbiSq6",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on \"Gradient-Based Learning Applied to Document Recognition\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP3uHEAliSq6",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "The review report is about giving an overview of the research paper- \"Gradient-Based Learning Applied to Document Recognition\" which designed an innovating and successful multi-module architecture called Graph Transform Network for pattern recognition and also evaluate the performance of the convolutional nerual network for identifying handwritten characters. The reson why this paper is selected to be analyzed is that this paper not only introduces how to achieve image identification/pattern recognition but also describe how to build a graph tranformer system in detail, which is good for the future study in deep learning and image \n",
        "processing, which also explains how gradient-based learning algorithm like CNN is feasible for image recognition. However, even many innovations and improvements were achieved in this research, there are still some limitaion of the research. In this review paper, firstly, the summarized content of the research will be described in the content section. Secondly, the innovation of the research will be explained detailly after the content section. Thridly, from the evaluation part of original paper, the technical quality will be talked about. Fourthly, this report will arrive to the application of the new technology. Finally, the last section will analyze how the author orgnized the report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afQWhuOKiSq7",
        "colab_type": "text"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z5hux4SiSq7",
        "colab_type": "text"
      },
      "source": [
        "In the past, most pattern recognition systems are built using a combination of automatic learning techniques and hand-crafted algorithms. This literature introduces two remarkable graph transform networks(GTN) with multi-modules for segmenting, classifying, and resequencing the handwritten characters string, which elistimates the manual work and increase the accuracy for the pattern recognition.On the one hand, the first GTN is combined by 4 modules the Segmentation Transformer, Character Recognition Transformer(CRT), Composition Transformer, and Beam Search Transformer. Specifically, the segmentation transformer will uses Heuristic Over-segmentaion algorithm to devide the whole picture to a set of arcs(segments) as the input of CRT. And then the CRT which is the most important part of the research is consitubed by the CNN trained with Gradient-based learning and back-propagation method. For training the CNN, such as the LeNet-5 with 7 layers as the innovated CNN described detailly in the research, the input image is very large and consists of many pixels. For example, a fully connected network with 100 hidden units contains thousands of weights. So, the CNN will use its particular function-convolution for extracting the feature data from the original image to be the feature maps, so that the gradient-based learning layer and back-propogation can handle the data.  Next, the author suggests to use the grammar graph and Viterbi algorithm to implement the composition transformer and the beam search transformer. \n",
        "\n",
        "On the other hand, the second GTN stucture uses the Space-Displacement Neural Network which is kind of CNN with the ability to automatic scan possible character positions of the orignal image to replace the segmentation transformer and Character Recognition Transformer. Besides, the compostion transfrom is separated to be two level compostion transformer-character and word level, because the identified characters of the SDNN's output sets is uncertained, which is depended on the identified possible positions of characters. For character level, with the help of CNN, the Hidden Markov Models(HMM) which is famous for classical speech recognition can be used in the character-level composition with reduced computational cost. For the word level, this GTN can be used for identified continiously on-line handwritten strings, so after transforming characters, the architure will recombinate the words with a language model and output the interpretation graph.                                                   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Firstly, the algorithm for extracting feature image from the original image is introduced step by step, which can generate the feature images for training, testing and verifying the model. Besides, the distinguished neural network - Convolutional Neural Network is designed by the authors in this paper for optimizing the pattern recognition rate.\n",
        "\n",
        "A combination of three factors have changed this vision over the last decade. First, the availability of low-cost machines with fast arithmetic units allows to rely more on brute-force ^numericaP, methods than on algorithmic refinements. Second, the availability of large databases for problems with a large market and wide interest, such as handwriting recognition, has enabled designers to rely more on real data and less on hand-crafted feature extraction to build recognition systems. The third and very important factor is the availability of powerful machine learning techniques that can handle high-dimensional inputs and can generate intricate decision functions when fed with these large data sets. It can be argued that the recent progress in the accuracy of speech and handwriting recognition systems can be attributed in large part to an increased reliance on learning techniques and large training data sets. As evidence to this fact, a large proportion of modern commercial OCR systems use some form of multi-layer Neural Network trained with back-propagation.\n",
        "\n",
        "\n",
        "Discriminative and non-discriminative gradient-based techniques for training a recognizer at the word level without requiring manual segmentation and labeling are presented in Section VI.\n",
        "\n",
        "\n",
        "Section VII presents the promising Space Displacement Neural Network approach that eliminates the need for segmentation heuristics by scanning a recognizer at all possible locations on the input.\n",
        "\n",
        "\n",
        "In section VIII, it is shown that trainable Graph Transformer Networks can be formulated as multiple generalized transductions, based on a general graph composition algorithm. The connections between GTNs and Hidden Markov Models, commonly used in speech recognition is also treated.\n",
        "\n",
        "Section IX describes a globally trained GTN system for recognizing handwriting entered in a pen computer. This problem is known as \"on-line” handwriting recognition, since the machine must produce immediate feedback as the user writes. The core of the system is a Convolutional Neural Network. The results clearly demonstrate the advantages of training a recognizer at the word level, rather than training it on pre-segmented, hand-labeled, isolated characters. Section X describes a complete GTN-based system for reading handwritten and machine-printed bank checks. The core of the system is the Convolutional Neural Network called LeNet-5 described in Section II.\n",
        "\n",
        "\n",
        "on-line  handwriting recognition\n",
        "\n",
        "\n",
        "  Gradient Back\u0003Propagation local minima do not seem to be a problem for multi-layer neural networks is somewhat of a theoretical mystery.non-linear gradient-based Learning techniques such as Boltzmann machines.\n",
        "  \n",
        "  The third event was the demonstration that the back-propagation procedure applied to multi-layer neural networks with sigmoidal units can solve complicated learning tasks.\n",
        "  \n",
        "  \n",
        "  The basic idea of back-propagation is that gradients can be computed efficiently by propagation from the output to the input. This idea was described in the control theory literature of the early sixties [16], but its application to machine learning was not generally realized then. Interestingly, the early derivations of back-propagation in the context of neural network learning did not use gradients, but ^virtual targets^ for units in intermediate layers [17], [18], or minimal disturbance arguments [19].\n",
        "  \n",
        "  \n",
        "  In this case, each module, called a Graph Transformer, takes one or more graphs as input, and produces a graph as output. Networks of such modules are called Graph Transformer Networks (GTN). Sections IV, VI and VIII develop the concept of GTNs, and show that Gradient-Based Learning can be used to train all the parameters in all the modules so as to mini\u001fmize a global loss function. It may seem paradoxical that gradients can be computed when the state information is represented by essentially discrete objects such as graphs, but that difficulty can be circumvented, as shown later.\n",
        "  \n",
        "  LeNet-5 including 7 layers for classifing single character.\n",
        "  \n",
        "  Multi\u0003Module Systems and Graph Transformer Networks       An Object\u0003Oriented Approach by each modules have the fprop(forward propagation) function, which is considered as a feed-forward network.\n",
        "\n",
        "\n",
        "Graph Transformer Networks by modules-Graph Transformer. Each module is designed for different task.Multiple Object Recognition: Heuristic Over-segmentation, Character Recognition.\n",
        "\n",
        "The recognition transformer Trec takes the segmentation graph Gseg as input\u0004 and applies the recognizer for single characters to the images associated with each of the arcs in the segmentation graph.\n",
        "\n",
        "sequence recognition systems training recurrent Neural networks is too hard with gradient-based techniques, therefore this paper suggest a simply method-the Viterbi algorithm\n",
        "\n",
        "\n",
        "Discriminative Viterbi Training GTN Architecture for a character string recognizer based on Heuristic Over-Segmentation. \n",
        "\n",
        "Multiple Object Recognition: Space Displacement Neural Network\n",
        "\n",
        "A Space Displacement Neural Network is a convolutional network that has been replicated over a wide input field\n",
        "In this paper  LeNet-5 SDNN is used for experimence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcrV1o8LiSq8",
        "colab_type": "text"
      },
      "source": [
        "## Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq8S26DliSq9",
        "colab_type": "text"
      },
      "source": [
        "The most important and intelligent innovation of the research is to use the CNN to elistimate the hand-crafted part, because before the research of the author, most pattren recognition system is built in a semi-automatic architecture, which means the graph feature extraction is manual work. Therefore, It is really remarkable for the importance and innovation of using the specialty of LeNet-5 CNN to achieve automatic feature map extracting and recognition in the research.\n",
        "\n",
        "In addition, there are two kind of GTNs that designed and experimented by the authors in the research. The authors seperate the whole transformer network to be modules by OOP method, and uses back-propagation method to compute the derivatives in the system. The innovation of the first GTN is to increase the accuracy of pattern recognition and combine the Heuristic Over-Segmentation, CNN, Viterbi algorithm and Grammar graph to fully automical transform the graph to be words. The innovation of the second GTN is to remove the segmentation part of the first GTN by using SDNN to replace the CNN and also use the HMM to achieve the characters recomposition module. \n",
        "\n",
        "What's more, the authors designed the generalized transduction for achieving the composition transform. The generalized transduction is divided as Check, Fprod, and Bprod function. For determining whether corresponding arc(s) should be created in the output graph, the Check function will compare the arcs(from recognition part) and output a boolean value. The Fprod function will be activated when the corresponding arc(s) should be built and creates new arcs and nodes between the up node and down node in the output new graph. The Bprod is called during training for propagating gradient data from the output subgraph to the data structures on the arc1 and arc2( from the recognition layer).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The main message of this paper is that better pattern recognition systems can be built by relying more on automatic learning, and less on hand-designed heuristics.\n",
        "\n",
        "Using document understanding as a case study, we show that the traditional way of building recognition systems by manually integrating individually designed modules can be replaced by a unified and well-principled design paradigm, called Graph Transformer Networks^ that allows training all the modules to optimize a global performance criterion.\n",
        "\n",
        "Since the early days of pattern recognition it has been known that the variability and richness of natural data, be it speech, glyphs, or other types of patterns, make it almost impossible to build an accurate recognition system entirely by hand. Consequently, most pattern recognition systems are built using a combination of automatic learning techniques and hand-crafted algorithms.\n",
        "\n",
        "\n",
        "The feature extractor contains most of the prior knowledge and is rather specific to the task. It is also the focus of most of the design effort, because it is often entirely hand-crafted. The classifier, on the other hand, is often general-purpose and trainable. One of the main problems with this approach is that the recognition accuracy is largely determined by the ability of the designer to come up with an appropriate set of features. This turns out to be a daunting task which, unfortunately, must be redone for each new problem. A large amount of the pattern recognition literature is devoted to describing and comparing the relative\n",
        "\n",
        "\n",
        "\n",
        "Convolutional Neural Networks introduced in Section II are an example of specialized neural network architectures which incorporate knowledge about the invariances of 2D shapes by using local connection patterns, and by imposing constraints on the weights.\n",
        "\n",
        "\n",
        "One of the most difficult problems in handwriting recog\u001fnition, however, is not only to recognize individual charac\u001fters, but also to separate out characters from their neigh\u001fbors within the word or sentence, a process known as seg\u001fmentation. The technique for doing this that has become the \"standard” is called **Heuristic Over-Segmentation**.\n",
        "\n",
        "\n",
        "Section V explores various ways to ensure that the loss function is dif\u001fferentiable, and therefore lends itself to the use of Gradient\u001fBased Learning methods. Section V introduces the use of directed acyclic graphs whose arcs carry numerical infor\u001fmation as a way to represent the alternative hypotheses, and introduces the idea of GTN.\n",
        "\n",
        "\n",
        "The second solution described in Section VII is to elim\u001finate segmentation altogether. The idea is to sweep the recognizer over every possible location on the input image, and to rely on the ^character spotting” property of the rec\u001fognizer, i.e. its ability to correctly recognize a well-centered character in its input field, even in the presence of other characters besides it, while rejecting images containing no centered characters [26], [27]. The sequence of recognizer outputs obtained by sweeping the recognizer over the in\u001fput is then fed to a Graph Transformer Network that takes linguistic constraints into account and finally extracts the most likely interpretation. This GTN is somewhat similar to Hidden Markov Models (HMM), which makes the ap\u001fproach reminiscent of the classical speech recognition [28], [29]. While this technique would be quite expensive in the general case, the use of Convolutional Neural Networks makes it particularly attractive because it allows significant savings in computational cost.\n",
        "\n",
        "\n",
        "\n",
        "Convolutional Neural Networks-----reduce the need for hand\u0003crafted heuristics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nqCJa4wrB7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOqtiUu6iSq9",
        "colab_type": "text"
      },
      "source": [
        "## Technical quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGPw647viSq-",
        "colab_type": "text"
      },
      "source": [
        "The technology of the research is in high quality. Generally speaking, the authors do the literature review for past methods to the pattern recognition for supporting that the pattern recognition is achieved by the hybrid-technology which combines automatic machine learning algorithm and manual feature extraction method. In the C part of the section I, the authors references several examples like the Boltzmann machines*** to prove that the multi-layer neural network achieved with gradient-back propagation algorithm is feasible for classifying non-linear objects, and the artificial image feature extraction can be replaced by the inner function of CNN. In my opinion, the quality of this part is good enough to explain why NN is reliable for handeling such non-linear classification.\n",
        "\n",
        "Besides, for explaining how CNN deal with 2D graph to be the OUTPUT, in the section II, the author draws the structure of the LeNet-5 CNN to show the inner cooperation between convolutions layers, subsampling layers, full connection layers and the output layer. For comparing the performance of CNN with other classifying algorithm, the author experimented more than 11 algorithm like SVM, K-NN, PCA, Tangent Distance and LeNet-1 to classify the single character image to be character, and the LeNet-5 shows the best performance(0.95% errors) without the help of articially distorted examples(LeNet-5 0.8% errors) and boosting method(LeNet-4 0.7% errors). In addition, the figure 13 of the section II shows the ability of LeNet-5 to identify the character from images with various degress of noisy conditions. What's more, For the GTN with SDNN approach, this hybrid and innovative architecture also tested with the normal and noised images, and provided with well-structured architecture diagram and algorithm coding like the generalized-composition function which is for compositing the recognized graphs to be a new graph. However, the GTNs sometimes still can not recognize some handwritten character because the written style of different people are different. So, in my opinion, the author should deal with this situation in the report or suggest some methodology for further research for this case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z-F2o36iSq_",
        "colab_type": "text"
      },
      "source": [
        "## Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LduLS9pIiSq_",
        "colab_type": "text"
      },
      "source": [
        "From the paper, it is known that this system is already used in the commercial area in the NCR Corporation line of the bank's check recognition systems which is used for recognizing the print or handwritten character from checks. The application has been realized and approved, because, in the United States, the system has read millions of checks per month in various banks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVADqy9OiSrA",
        "colab_type": "text"
      },
      "source": [
        "## Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oJfVdQLiSrB",
        "colab_type": "text"
      },
      "source": [
        "The overall structure of the paper is well. The authors explain several fundemantal knowledages about the old-fashioned pattern recognition system and the new technologies in the introduction part                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
        "The overall strucutre is clear. I found reading is easy / difficult. The paper could have been more attractive if the authors had organised ... / provided ... \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFAaLVfViSrB",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "[SHA48][1]: Author, Title, Info\n",
        "\n",
        "[1]:https://google.com"
      ]
    }
  ]
}